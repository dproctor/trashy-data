---
title: Impact of Clean Up The City on sidewalk cleanliness
---

We begin by joining the two datasets published by DPW(<https://data.sfgov.org/City-Infrastructure/DPW-Street-Sidewalk-Evaluation-Results-CY22/fsqv-4vqv/about_data>, <https://data.sfgov.org/City-Infrastructure/Street-Sidewalk-Maintenance-Standards-Results-Jan-/qya8-uhsz/about_data>), as neither is a proper subset of the other.

Unfortunately, the second dataset is missing precise locations. I emailed SF gov to see if this can be fixed. The alternative would be to manually add GPS coordiantes for 2,607 more observations.

```
TODO(devon): revisit once this is confirmed.
```

```{python}
#| title: Look at schema
#| echo: false
#| output: false
import polars as pl

with pl.Config(tbl_cols=-1, tbl_width_chars=1000):
  print(pl.read_csv("data/DPW_Street___Sidewalk_Evaluation_Results__CY22_20241122.csv").describe())
  print(pl.read_csv("data/Street___Sidewalk_Maintenance_Standards_Results__Jan_2022-Jun_2024_20241209.csv").describe())
```

```{python}
#| title: Join old and new datasets
old_dataset = pl.read_csv("data/DPW_Street___Sidewalk_Evaluation_Results__CY22_20241122.csv").select(
    pl.col("ObjectID").alias("object_id"),
    pl.col("Route ID:").alias("route_id"),
    pl.col("Select the statement that best describes the amount and distribution of litter on the sidewalk.").alias("sidewalk_litter"),
    pl.col("CreationDate").str.to_datetime("%m/%d/%Y %I:%M:%S %p").alias("evaluation_date"),
    pl.col("the_geom").replace("POINT (0 0)", None).alias("geom"),
    pl.col("Route Location:").alias("route_location"),
    pl.lit("old").alias("dataset"),
  )
new_dataset = pl.read_csv("data/Street___Sidewalk_Maintenance_Standards_Results__Jan_2022-Jun_2024_20241209.csv").select(
    pl.col("ObjectID").alias("object_id"),
    pl.col("Route ID:").alias("route_id"),
    pl.col("Select the statement that best describes the amount and distribution of litter on the sidewalk.").alias("sidewalk_litter"),
    pl.col("CreationDate").str.to_datetime("%m/%d/%Y %I:%M:%S %p").alias("evaluation_date"),
    pl.lit(None).alias("geom"), # missing precise location data :/
    pl.col("Route Location:").alias("route_location"),
    pl.lit("new").alias("dataset"),
  )

data = pl.concat([old_dataset, new_dataset]).unique(subset=["object_id", "route_id"], keep="first")

data = data.join(
  pl.read_csv("data/manual-geoms.csv"), on=["object_id", "route_id"], how="left"
).with_columns(
  pl.coalesce(pl.col(["geom", "geom_right"])).alias("geom")
).drop("geom_right")

data.describe()

# data.sort("evaluation_date").write_csv("/tmp/dups.csv")
```


We see that there is decent support in the time period that Clean Up the City has been active.

```{python}
import matplotlib.pyplot as plt
import seaborn as sns

plt.xticks(rotation=30)
sns.histplot(data=data, x="evaluation_date")
```
